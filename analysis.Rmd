---
title: "Impact Analysis"
date: "`r paste0('Last Updated: ', format(Sys.time(), '%d %B, %Y')) `"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
editor_options: 
  chunk_output_type: console
---

```{r setup, include = F}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
knitr::opts_chunk$set(fig.align = 'center')

library(tidyverse)
library(patchwork)
library(pdwtheme)
library(gt)
library(infer)
# To Turn off Scientific Notation Use this.
options(scipen = 999)

source("./src/looma_theme.R")

dat <- read_csv(here::here("data-raw", "looma_audition_data.csv"))

```


# Executive Summary {.tabset .tabset-pills}

<div class = "summaryblock">

## Prompt

__Prompt:__

Imagine we ran an experiment to test the impact a Loop™ campaign has on sales. The experiment involved 42 stores in 3 groups:  

* _“Program test”_  These stores had the full Loop™ campaign as it would normally run, with a display of featured products and a tablet showing 2-3 films in a looping playlist  
* _“Film control”_  These stores had the full program but with the film from one brand (“Brewery A”) left out.   
* _“Baseline control”_  These stores did not have Loop™ campaigns or featured products on display.  

Assume you need to provide an analysis of this experiment under time constraints (in reality, we expect you to devote 2-4 hours to this audition project).

## Goal  

__Goal:__  

We want to know the impact the Loop™ campaign had on sales. By comparing the different groups we would like to learn a few different things:  

* Is there an impact of the "Brewery A" Loop™ Campaign on sales?
    * If we see that the "program_test" condition has increased sales as compared to both the baseline and the "film_control" condition we can be confident that it was Brewery A's film that had the affect on sales and not just the slick Loop™ campaign ipad with the other videos.
* If so what is the impact? (Sales amount vs sales dollars)

 
## Assumptions 

__Assumptions:__
_(Note: this section would likely take a different shape as familiarity with the data source increase/ relationship with the customer develops)_ 

With this analysis we are assuming that: 

* The type/size of stores are similar for the across the 3 groups. (ie if the groups were stratified by size then the resulting sales could be more a factor of store size and less the campaign)
* The store regions are similar enough (ie the campaign might not be relevant to certain communities or the communities could be in different SES leading to different reactions to the pandemic). 
* The potential time of year impact is captured similarly across the 3 groups (ie if beer/wine is most popular during Thanksgiving/ 4th of July, that the store groups capture that time period similarly across groups).
* The beers made available by Brewery A were consistent across stores, and were placed in a relatively similar proximity to the Loop™/ were accessible to the customer.


 
## Results

__Results:__  
From the analysis we find that:

1. Overall the Loop™ campaign looks to had a positive impact on Brewery A's sales.  
1. The sales increased year over year for all groups.  
    * This could mean that the brand awareness for the Brewery has generally increased over time.
    * Could be a Covid affect (more people trying beer) or that there were more options made available to customers over time.
1. The "program test" both show an increase in the mean sales (both amount and dollars) as compared to the baseline and the film control.  
    * For this sample, it looks like the Loop™ campaign __increased Brewery A sales on average by ~$15__ (roughly 1 additional unit) on average as compared to the baseline  


__Potential Investigation Next Steps:__ 

* It would be interesting in future iterations, to get a more detailed view of what is being purchased. This could potentially help to understand where the campaign leads to the purchase of (perceived) similar products. 
* Depending on who the customer is, we might want to calculate the ROI of the Loop™ campaign 
* It would be interesting figure out the "0's" (ie getting total people who went to the store but didn't buy that beer, helping to understand if they bought different beer/wine).
* With the variations in sales amount vs dollars it would be interesting to get increase visibility to other potential confounding affects (ie sales).

</div>


# Summary of Impact {.tabset .tabset-pills}

## Avg Velocity Amount (Sales $)

```{r}
pval <- dat %>%
  specify(weekly_velocity_amount ~ store_group) %>%
  hypothesize(null = "independence") %>%
  generate(reps = 10000, type = "permute") %>%
  calculate(stat = "F") %>%
  get_p_value(obs_stat = dat %>%
                specify(weekly_velocity_amount ~ store_group) %>%
                calculate(stat = "F"),
              direction = "greater")%>% 
  mutate(pval = ifelse(p_value < 0.001, "<0.001", scales::comma(p_value, accuracy = 0.0001)))


```


When grouping all of the years together by experimental condition ("store_group"), we see that the by-period sales are higher on average when the Loop™ campaign is fully utilized for Brewery A.

To understand if the differences could be due to random chance, we use an ANOVA to see if the differences in the group means are statistically significant. With a resulting p-value of __`r pval$pval`__, we can conclude that the sale dollars are positively impacted by the campaign.

The visual below helps us to understand of the nature of the sale distribution varies for the different conditions.  

* For example we see the widest part of the baseline group is around `$30-40` indicating that the majority of the sales occur in that range (though sometimes sales exceed $200).
* In contrast the widest part of the "program_test" group is above `$50`, indicating that a high degree of the average weekly Brewery A sales in stores with the Loop™ are frequently higher than the baseline stores.

<div class = "row">
<div class = "col-md-8">

```{r, out.width="100%"}
summary <- dat %>% 
  group_by(store_group) %>% 
  summarise(avg_amnt = mean(weekly_velocity_amount),
            n = n(),
            std_amnt = sd(weekly_velocity_amount))

dat %>% 
  ggplot(aes(store_group, weekly_velocity_amount, fill = store_group, color = store_group))+
    geom_jitter(size = 0.5, width = .3)+
    geom_violin(alpha=0.7)+
    geom_point(data = summary, aes(store_group, avg_amnt), color= "black", size = 2.5)+
    labs(title = "Comparison of Weekly Velocity Amount ($ Sales) by Store Group (Condition)",
         subtitle = "Points represent average weekly sales per promo period",
         caption = "Black point represent the groups average",
         x= NULL, y= "Average Weekly Sales")+
    scale_y_continuous(labels = scales::dollar, breaks = seq(0,300, 50))+
    scale_fill_pdw()+
    scale_color_pdw()+
    looma_theme()+
    theme(legend.position = "none")

```


</div>
<div class = "col-md-4">

```{r, fig.width=4}
summary %>% 
  gt() %>% 
  fmt_currency(columns = c(2,4), decimals = 2)%>% 
  cols_move(
    columns = vars(n),
    after = vars(std_amnt)
  ) %>%
  cols_label(
    store_group = "Store Group",
    avg_amnt = "Group Average",
    std_amnt = "Group SD",
    n = "Total Periods"
  ) %>%
  tab_header(
    title = md("Summary of Average Weekly Sales"),
    subtitle = "For Brewery A's Loop Campaign"
  ) %>% 
  tab_options(
    container.width = "110%"
  )
```

</div>
</div>


## Avg Velocity Quantity (Sale Units) 

```{r}
pval <- dat %>%
  specify(weekly_velocity_quantity ~ store_group) %>%
  hypothesize(null = "independence") %>%
  generate(reps = 10000, type = "permute") %>%
  calculate(stat = "F") %>%
  get_p_value(obs_stat = dat %>%
                specify(weekly_velocity_quantity ~ store_group) %>%
                calculate(stat = "F"),
              direction = "greater") %>% 
  mutate(pval = ifelse(p_value < 0.001, "<0.001", scales::comma(p_value, accuracy = 0.0001)))


```



When grouping all of the years together by experimental condition ("store_group"), we see that the by-period sales are higher on average when the Loop™ campaign is fully utilized for Brewery A.

To understand if the differences could be due to random chance, we use an ANOVA to see if the differences in the group means are statistically significant. With a resulting p-value of __`r pval$pval`__, we can conclude that the sale amounts are positively impacted by the campaign. 

<div class = "row">
<div class = "col-md-8">


```{r, out.width="100%"}
summary <- dat %>% 
  group_by(store_group) %>% 
  summarise(avg_amnt = mean(weekly_velocity_quantity),
            n = n(),
            std_amnt = sd(weekly_velocity_quantity))

dat %>% 
  ggplot(aes(store_group, weekly_velocity_quantity, fill = store_group, color = store_group))+
    geom_jitter(size = 0.5, width = .3)+
    geom_violin(alpha=0.7)+
    geom_point(data = summary, aes(store_group, avg_amnt), color= "black", size = 2.5)+
    labs(title = "Comparison of Weekly Velocity Quantity by Store Group",
         subtitle = "Points represent average weekly sales per promo period",
         caption = "Black point represent the groups average",
         x = NULL, y= "Weekly Sales")+
    scale_fill_pdw()+
    scale_color_pdw()+
    looma_theme()+
    theme(legend.position = "none")
```

</div>
<div class = "col-md-4">

```{r}
summary %>% 
  gt() %>% 
  fmt_number(columns = c(2,4), decimals = 1) %>% 
  cols_move(
    columns = vars(n),
    after = vars(std_amnt)
  ) %>%
  cols_label(
    store_group = "Store Group",
    avg_amnt = "Group Average",
    std_amnt = "Group SD",
    n = "Total Periods"
  ) %>%
  tab_header(
    title = md("Summary of Weekly Units"),
    subtitle = "For Brewery A's Loop Campaign"
  ) %>% 
  tab_options(
    container.width = "110%"
  )
```

</div>
</div>


## Avg Sale Dollars By Year

Below we have two different views of the trends over time

```{r, out.width="100%", fig.width=12}
summary <- dat %>% 
  mutate(period_year = as.factor(period_year)) %>% 
  group_by(store_group, period_year) %>% 
  summarise(avg_amnt = mean(weekly_velocity_quantity),
            n = n(),
            std_amnt = sd(weekly_velocity_quantity))

dat %>% 
  mutate(period_year = as.factor(period_year)) %>% 
  ggplot(aes(period_year, weekly_velocity_quantity, fill = period_year, color = period_year))+
    geom_jitter(size = 0.5, width = .3)+
    geom_violin(alpha=0.7)+
    geom_point(data = summary, aes(period_year, avg_amnt), color= "black", size = 2.5)+
    labs(title = "Average Weekly Sales by Store Group and Year")+
    scale_fill_pdw()+
    scale_color_pdw()+
    looma_theme()+
    facet_wrap(store_group ~ ., ncol =3)+
    # theme(strip.background = element_rect(color = "grey"))+
    NULL

```


```{r, out.width="100%", fig.width=12}
dat %>% 
  mutate(date_us_week = as.Date(paste(period_year, period_num * 4, 1), format = "%Y %U %u")) %>% 
  group_by(date_us_week,period_year, store_group ) %>% 
  summarize(avg_amnt = mean(weekly_velocity_quantity),
            avg_dol = mean(weekly_velocity_amount),
            sd_dol = sd(weekly_velocity_amount)) %>% 
  ggplot(aes(date_us_week, avg_dol, color = store_group, group = store_group))+
    geom_line(size = 1.2, color = "grey")+
    geom_point(size = 2)+
    geom_errorbar(aes(ymin = avg_dol - sd_dol, ymax = avg_dol + sd_dol), width = 9, position = "dodge")+
    labs(title = "Avg Weekly Dollars For Store Group Over Time",
         subtitle = "Points representing the mean for all stores || Error bars showing +/- 1SD for that period ",
         caption = "Assuming that periods are distributed equally throughout the year to convert to dates",
         x = NULL, y=NULL, color = NULL)+
    scale_fill_pdw()+
    scale_color_pdw()+
    scale_y_continuous(labels = scales::dollar, breaks = seq(0,300, 25))+
    scale_x_date(date_breaks = "1 months")+
    looma_theme()+
    facet_wrap(period_year ~ ., ncol =3, scales = "free_x")+
    theme(axis.text.x = element_text(angle = 60))+
    NULL

```


